\section{Resilient Distributed Datasets. Мотивация, реализация,
  секционирование датасетов, материализация датасетов.}

\textbf{Мотивация.}
\begin{itemize}
  \item Удобно производить вычисления, последовательно выполняя \texttt{map},
    \texttt{filter} и \texttt{flatMap}. Однако, каждая операция требует работу с
    дисокм для сохранения промежуточных данных, которые не нужны в конечном
    результате.
  \item В итеративных алгоритмах (напр. локальные оптимизаторы, графовые
    алгоритмы, алгоритмы связанные с Марковскими цепями) на каждом шаге данные
    преобразуются и сохраняются, что понижает производительность из-за активной
    работы с диском.
\end{itemize}

\lstset{
    language=Python,
    backgroundcolor=\color{black!5}, % set backgroundcolor
    basicstyle=\footnotesize,% basic font setting
}

\begin{example}(Ленивые вычисления)

Хотим посчитать:
  \begin{lstlisting}
result = datasource.fetch()
                   .map(...)
                   .filter(...)
                   .flatMap(...)
                   .collect(...)
  \end{lstlisting}

Обозначим \texttt{f} --- \texttt{map}, \texttt{p} --- \texttt{filter}, \texttt{g} --- \texttt{flatMap}.

\textbf{Плохая реализация:}

  \begin{lstlisting}
data = datasource.fetch()

mapped = []
for elem in data:
    mapped.add(f(elem))

filtered = []
for elem in mapped:
    filtered.add(elem) if p(elem)

result = []
for elem in filtered:
    result.addAll(g(elem))
  \end{lstlisting}

  Если считать результат на каждом шаге, то на диске аллоцируется много ненужных коллекций (\texttt{mapped, filtered}).

\textbf{Оптимальная реализация:}
  \begin{lstlisting}
result = []

for elem in datasources.fetch():
    mapped = f(elem)
    if p(mapped):
        result.addAll(g(mapped))
  \end{lstlisting}

Аллоцировали на диске только одну коллекцию --- \texttt{result}.
\end{example}

\begin{remark} Данная идея реализована в:
  \begin{itemize}
    \item Java streams,
    \item Haskell stream fusion,
    \item Python generators.
  \end{itemize}
\end{remark}

\begin{algorithm}(Последовательная реализация)
  \begin{itemize}
    \item Результат каждой операции --- ленивый контейнер.
    \item Каждый контейнер хранит только операцию, с помощью которой он был
      получен, и список других контейнеров, из которых он был получен.
  \end{itemize}
\end{algorithm}

\begin{algorithm}(Распределенная реализация: Resilient Distributed Datasets)
  \begin{itemize}
    \item Датасет шардируется по строкам на несколько секций. В зависимости от шардирования (по ключу или по значению), некоторые
      операции смогут производиться локально, без использования сети (напр. \texttt{groupByKey} при шардировании по ключу).
    \item Для каждой секции известно, с помощью какой операции и из каких секций родительского датасета она была посчитана.
    \item В случае сбоя, утраченную секцию можно пересчитать, поскольку
      известна операция и секции родителя, к которым ее необходимо применить.
      По возможности, это можно сделать параллельно.
    \item В отдельных случаях датасет нужно в явном виде посчитать и сохранить, то есть \textit{материализовать}:
      \begin{itemize}
        \item если требуется совершить несколько запросов,
        \item если из датасета будет построено более одного производных,
        \item если требуется создать контрольную точку для ускорения
          восстановления после сбоя,
        \item если операция этого требует (напр. сортировка).
      \end{itemize}
      Материализацию можно производить как на диск, так и в ОЗУ, в зависимости
      от целей пользователя. Также можно материализовывать только отдельные
      секции.
  \end{itemize}
\end{algorithm}

\begin{remark} Алгоритм работает в доверенных сетях и не приспособлен для
  работы с <<византийскими>> процессами.
\end{remark}
