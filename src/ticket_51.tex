\section{Resilient Distributed Datasets. Мотивация, реализация,
  секционирование датасетов, материализация датасетов.}

\textbf{Мотивация.}
\begin{itemize}
  \item Удобно производить вычисления, последовательно выполняя \texttt{map},
    \texttt{filter} и \texttt{flatMap}. Однако, каждая операция требует работу с
    дисокм для сохранения промежуточных данных, которые не нужны в конечном
    результате.
  \item В итеративных алгоритмах (напр. локальные оптимизаторы, графовые
    алгоритмы, алгоритмы связанные с Марковскими цепями) на каждом шаге данные
    преобразуются и сохраняются, что понижает производительность из-за активной
    работы с диском.
\end{itemize}

\lstset{
    language=Python,
    backgroundcolor=\color{black!5}, % set backgroundcolor
    basicstyle=\footnotesize,% basic font setting
}

\begin{example}(Ленивые вычисления: плохая реализация)
  \begin{lstlisting}
data = datasource.fetch()

mapped = []
for elem in data:
    mapped.add(f(elem))

filtered = []
for elem in mapped:
    filtered.add(elem) if p(elem)

result = []
for elem in filtered:
    result.addAll(g(elem))
  \end{lstlisting}
\end{example}

\begin{example}(Ленивые вычисления: оптимальная реализация)
  \begin{lstlisting}
result = []

for elem in datasources.fetch():
    mapped = f(elem)
    if p(mapped):
        result.addAll(g(mapped))
  \end{lstlisting}
\end{example}

\begin{remark} Данная идея реализована в:
  \begin{itemize}
    \item Java streams,
    \item Haskell stream fusion,
    \item Python generators.
  \end{itemize}
\end{remark}

\begin{algorithm}(Последовательная реализация)
  \begin{itemize}
    \item Результат каждой операции --- ленивый контейнер.
    \item Каждый контейнер хранит только операцию, с помощью которой он был
      получен, и список других контейнеров, из которых он был получен.
  \end{itemize}
\end{algorithm}

\begin{algorithm}(Распределенная реализация: Resilient Distributed Datasets)
  \begin{itemize}
    \item Датасет шардируется по строкам на несколько секций. В зависимости от
      выбора, по чему производится шардирование (ключ или значение), некоторые
      операции смогут производиться локально, без использования сети (напр.
      % КОСТЫЛЬ
      \newline \texttt{groupByKey} при шардировании по ключу).
    \item После операции получаем из родительских секций производные секции.
      В каждой производной секции хранится, с помощью какой операции и из каких
      родительских датасетов она была посчитана.
    \item В случае сбоя, утраченную секцию можно пересчитать, поскольку
      известно, с помощью каких операций и из каких секций она была посчитана.
      По возможности, это можно сделать параллельно.
    \item В отдельных случаях промежуточные вычисления выполняются энергично
      (датасет материализуется):
      \begin{itemize}
        \item если требуется совершить несколько запросов,
        \item если из датасета будет построено более одного производных,
        \item если требуется создать контрольную точку для ускорения
          восстановления после сбоя,
        \item если операция этого требует (напр. сортировка).
      \end{itemize}
      Материализацию можно производить как на диск, так и в ОЗУ, в зависимости
      от целей пользователя. Также можно материализовывать только отдельные
      секции.
  \end{itemize}
\end{algorithm}

\begin{remark} Алгоритм работает в доверенных сетях и не приспособлен для
  работы с <<византийскими>> процессами.
\end{remark}
